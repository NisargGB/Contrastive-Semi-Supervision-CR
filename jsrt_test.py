# -*- coding: utf-8 -*-
"""train_anti_celiac.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BpuYFF1SGAfv4XYgDUFAqqj3HEfTGbwN
"""

import os
from utils import output2image
#os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
# os.environ["CUDA_VISIBLE_DEVICES"]="0"
from jsrt_data_generator import JSRT_Loader as DataGenerator
from model import attention_unet_refined, attention_unet_resnet50
from metrics import *
import time
import random
from  tqdm import tqdm

import numpy as np
import tensorflow as tf
from tensorflow.keras.metrics import Precision, Recall, MeanIoU
from tensorflow.keras.optimizers import Adam, Nadam, SGD

## Path
weights_paths = ['/scratch/cse/btech/cs1170354/BTP2/weights/jsrt_weights.h5']
results_folder = 'Results/jsrt'
encoder_weights = None


folder_path = '/scratch/cse/btech/cs1170354/BTP2/Data/jsrt'
# train_path = "D:/Master/Study/Semester7/BTP1/Data/Train"

## Parameters
image_size = (256, 256) # Original = (2448, 1920)
batch_size = 16
mode = 'seg'
target_classes = ["heart", "left clavicle", "right clavicle", "left lung", "right lung"]
filter_classes = []    # Train only with items containing them
freeze_encoder = False
freeze_decoder = False
load_last_layer = True
lr = 1e-3
epochs = 500

# att_unet = attention_unet_resnet50(input_shape=(image_size[0], image_size[1], 3)
#                                 , out_channels=len(target_classes)
#                                 , freeze_encoder=freeze_encoder
#                                 , encoder_weights=encoder_weights
#                                 , freeze_decoder=freeze_decoder
#                                 , dropout_rate=0.0)
encoder, att_unet, localizer, anticeliac, mask_inputs = attention_unet_refined(image_size, 
                                                                                3, 
                                                                                3, 
                                                                                multiplier=8, 
                                                                                freeze_encoder=freeze_encoder, 
                                                                                freeze_decoder=freeze_decoder, 
                                                                                use_constraints = False, 
                                                                                dropout_rate=0.0)
if mode == 'seg':
    model = att_unet
    metrics = [uniclass_dice_coeff_0, uniclass_dice_coeff_1, uniclass_dice_coeff_2, multiclass_dice_coeff]
    losses = multiclass_dice_loss(loss_scales=[1., 1., 1.])
    # losses = focal_tversky_loss

optimizer = Adam(learning_rate=lr)
model.compile(loss=losses, optimizer=optimizer, metrics=metrics)
model.summary()

# Resume from checkpoint
if weights_paths != []:
    for wp in weights_paths:
        if load_last_layer:
            model.load_weights(wp, by_name=True)
        else:
            _, temp_model, _, _, _ = attention_unet_refined(image_size, 
                                                            3, 
                                                            1, 
                                                            multiplier=10, 
                                                            freeze_encoder=freeze_encoder, 
                                                            freeze_decoder=freeze_decoder, 
                                                            use_constraints = False, 
                                                            dropout_rate=0.0)
            temp_model.load_weights(wp, by_name=True)
            for i in range(len(model.layers)):
                if model.layers[i].name != 'conv1x1':
                    model.layers[i].set_weights(temp_model.layers[i].get_weights())


# Data generators
train_generator = DataGenerator(folder_path, ['fold1'], image_size, batch_size, mode='seg', target_classes=target_classes
                            , filter_classes=[], augment=True)
val_generator = DataGenerator(folder_path, ['fold2'], image_size, batch_size, mode='seg', target_classes=target_classes
                            , filter_classes=[], augment=False)


for batchno in tqdm(range(len(val_generator))):
    inps, tgts = val_generator[batchno]
    preds = model.predict_on_batch(inps)

    bs, w, h, c = tgts.shape
    for i in range(bs):
        input_img = output2image(inps[i])
        pred_mask = output2image((preds[i].numpy() >= 0.5) * 1.)
        gt_mask = output2image(tgts[i])

        combined_img = Image.new('RGB', (w*3 + 20, h))
        divider = Image.new('RGB', (10, h), (255, 255, 255))
        combined_img.paste(input_img, (0, 0))
        combined_img.paste(divider, (w, 0))
        combined_img.paste(pred_mask, (w + 10, 0))
        combined_img.paste(divider, (w*2 + 10, 0))
        combined_img.paste(gt_mask, (w*2 + 20, 0))
        combined_img.save(results_folder + '/{}.png'.format(str(batchno) + '-' + str(i)))
